{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Name:Pavithra S\n",
    "Reg:225229125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Document Similarity using Doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[\"I love machine learning. Its awesome.\",\n",
    "\"I love coding in python\",\n",
    "\"I love building chatbots\",\n",
    "\"they chat amagingly well\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Create TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data=[TaggedDocument(words=word_tokenize(d.lower()),tags=[str(i)]) for i,d in enumerate(data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "#model parameters\n",
    "vec_size=20\n",
    "alpha=0.025\n",
    "\n",
    "#create model\n",
    "model=Doc2Vec(vector_size=vec_size,\n",
    "             alpha=alpha,\n",
    "             min_alpha=0.00025,\n",
    "             min_count=1,\n",
    "             dm=1)\n",
    "\n",
    "#build vocabulary\n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "#shuffle data\n",
    "tagged_data=utils.shuffle(tagged_data)\n",
    "\n",
    "#train Doc2Vec model\n",
    "model.train(tagged_data,\n",
    "        total_examples=model.corpus_count,\n",
    "        epochs=30)\n",
    "\n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Find Similar documents for the given document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1_infer [-0.00628174  0.01117978  0.0078928   0.02358329  0.0240783   0.0241926\n",
      "  0.01790185  0.01491485 -0.01218563  0.00336643 -0.00813564  0.00505789\n",
      "  0.00430344  0.00052596  0.00542781 -0.01847247 -0.01744725 -0.02444072\n",
      " -0.02125897  0.02318843]\n",
      "[('2', 0.3250403106212616), ('0', 0.2968985438346863), ('3', 0.22365665435791016)]\n",
      "[-0.01990577  0.01304763 -0.02958454  0.01350018  0.03025302 -0.0416232\n",
      " -0.0429488  -0.05067174  0.0239734  -0.04663915  0.02936365  0.03494433\n",
      " -0.0342547  -0.02422205 -0.00711292  0.00778666 -0.00734602 -0.04273351\n",
      " -0.01970573  0.00895928]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "model=Doc2Vec.load(\"d2v.model\")\n",
    "\n",
    "#to find the vector of a document which is not in training data\n",
    "\n",
    "test_data=word_tokenize(\"I love chatbots\".lower())\n",
    "v1=model.infer_vector(test_data)\n",
    "print(\"v1_infer\",v1)\n",
    "\n",
    "#to find most similar doc using tags\n",
    "similar_doc=model.dv.most_similar('1')\n",
    "print(similar_doc)\n",
    "\n",
    "#to find vector of doc in training data using tags or\n",
    "#In other words,printing the vector of document at index 1 in training data\n",
    "\n",
    "print(model.dv[\"1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question-1. Train the following documents using Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\"the house had a tiny little mouse\",\n",
    "        \"the mouse ran away from the house\",\n",
    "        \"the cat finally ate the mouse\",\n",
    "        \"the end of the mouse story\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_docs=[TaggedDocument(words=word_tokenize(d.lower()),tags=[str(i)]) for i,d  in enumerate(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "#model parameters\n",
    "vec_size=20\n",
    "alpha=0.025\n",
    "\n",
    "#create model\n",
    "model=Doc2Vec(vector_size=vec_size,\n",
    "             alpha=alpha,\n",
    "             min_alpha=0.00025,\n",
    "             min_count=1,\n",
    "             dm=1)\n",
    "\n",
    "#build vocabulary\n",
    "model.build_vocab(tagged_docs)\n",
    "\n",
    "#shuffle data\n",
    "tagged_docs=utils.shuffle(tagged_docs)\n",
    "\n",
    "#train Doc2Vec model\n",
    "model.train(tagged_docs,\n",
    "           total_examples=model.corpus_count,\n",
    "           epochs=30)\n",
    "\n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1_infer [ 0.01325687 -0.01836687  0.00975062  0.02452783  0.02382731 -0.01649335\n",
      " -0.00994847  0.01145699  0.01769195 -0.01408347  0.01660025 -0.01438435\n",
      " -0.01571622 -0.01222706 -0.00617121  0.01248548 -0.0068709  -0.00465107\n",
      "  0.01529026 -0.00246679]\n",
      "[('3', 0.3407185971736908), ('1', 0.33049604296684265), ('0', -0.1114959642291069)]\n",
      "[-0.0107779  -0.03629022  0.02062683 -0.0430157   0.01423227 -0.02366377\n",
      "  0.00278364 -0.0108782   0.02691032 -0.04073556 -0.01055875 -0.00018295\n",
      " -0.03411321 -0.03360157 -0.01021269  0.04415133 -0.00633329  0.01769288\n",
      " -0.02959119  0.04442726]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "model=Doc2Vec.load(\"d2v.model\")\n",
    "\n",
    "#to find the vector of a document which is not in training data\n",
    "test_data=word_tokenize(\"cat stayed in the house\".lower())\n",
    "v1=model.infer_vector(test_data)\n",
    "print(\"v1_infer\",v1)\n",
    "\n",
    "#to find most similar doc using tags\n",
    "similar_doc=model.dv.most_similar('2')\n",
    "print(similar_doc)\n",
    "\n",
    "#to find vector of doc in training data using tags\n",
    "print(model.dv[\"2\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
